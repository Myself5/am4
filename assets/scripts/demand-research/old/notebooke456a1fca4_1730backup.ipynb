{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport os\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('device:', device)\n\nif device.type == 'cuda':\n    print(torch.cuda.get_device_name(0))\n    print(' Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n    print(' Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:29:23.552896Z","iopub.execute_input":"2023-04-19T08:29:23.554194Z","iopub.status.idle":"2023-04-19T08:29:23.562596Z","shell.execute_reply.started":"2023-04-19T08:29:23.554131Z","shell.execute_reply":"2023-04-19T08:29:23.561353Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"device: cuda\nTesla P100-PCIE-16GB\n Allocated: 0.0 GB\n Cached:    0.0 GB\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport matplotlib.pyplot as plt\nimport math\nimport numpy as np\nimport time\nimport json\nimport os\nif not os.path.exists('models'):\n    os.mkdir('models')\n\ntorch.manual_seed(3)\nplt.style.use('dark_background')\nplt.rcParams['axes.prop_cycle'] = plt.cycler(color=plt.cm.rainbow(np.linspace(0, 1, 5)))\n\nN = 3983\nA0 = torch.load('../input/am4-default/A-V4_3.pt', map_location='cuda')\ncapital_ids = torch.load('../input/am4-default/capital_ids.pt', map_location='cuda')\nAs = torch.stack([A0, torch.zeros(N, dtype=torch.float32).cuda()])\nD = torch.load('../input/am4-default/D.pt', map_location='cuda')\n\nmask = ~torch.eye(N, dtype=bool).cuda()\nys = D[mask].reshape(-1)\n\nmask = mask.view(-1)\ni = torch.arange(N, device='cuda').repeat(N)[mask]\nj = torch.arange(N, device='cuda').repeat_interleave(N)[mask]\n\nxs = torch.stack((i, j), dim=1) # [[i0, j0], ...]","metadata":{"execution":{"iopub.status.busy":"2023-04-19T08:45:47.882412Z","iopub.execute_input":"2023-04-19T08:45:47.882896Z","iopub.status.idle":"2023-04-19T08:45:47.983847Z","shell.execute_reply.started":"2023-04-19T08:45:47.882861Z","shell.execute_reply":"2023-04-19T08:45:47.982845Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"tensor([[   1,    2,    3,  ..., 3979, 3980, 3981],\n        [   0,    0,    0,  ..., 3982, 3982, 3982]], device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"batch = torch.tensor([[3, 999], [4, 3320], [3, 3320]]).cuda()\nbatch_ij = batch.t()\n\ni, j = batch_ij\nicap, jcap = torch.isin(batch_ij, capital_ids).to(torch.int64)\nprint(i, j)\nprint(icap, jcap)\n\nprint('As', As)\nAi = torch.index_select(As, 1, i)\nA = torch.gather(Ai, 0, icap.unsqueeze(0))\nprint(Ai)\nprint(A)\n# print(iin)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T09:08:42.615588Z","iopub.execute_input":"2023-04-19T09:08:42.616273Z","iopub.status.idle":"2023-04-19T09:08:42.631879Z","shell.execute_reply.started":"2023-04-19T09:08:42.616235Z","shell.execute_reply":"2023-04-19T09:08:42.630580Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"tensor([3, 4, 3], device='cuda:0') tensor([ 999, 3320, 3320], device='cuda:0')\ntensor([1, 0, 1], device='cuda:0') tensor([0, 1, 1], device='cuda:0')\nAs tensor([[ 0.0000, 24.3011,  6.3601,  ..., 13.7397, 13.6036, 23.2647],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n       device='cuda:0', grad_fn=<StackBackward0>)\ntensor([[26.2364,  7.1814, 26.2364],\n        [ 0.0000,  0.0000,  0.0000]], device='cuda:0',\n       grad_fn=<IndexSelectBackward0>)\ntensor([[0.0000, 7.1814, 0.0000]], device='cuda:0', grad_fn=<GatherBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"class DemandModel(nn.Module):\n    def __init__(self):\n        super(DemandModel, self).__init__()\n        self.As = nn.Parameter(As)\n        self.Bs = nn.Parameter(torch.zeros((2, N)))\n#         self.A = nn.Parameter(torch.rand(N) * 25)\n        self.B = nn.Parameter(torch.rand(N) * 3)\n#         self.C = nn.Parameter(torch.rand(N) * 25)\n#         self.M = nn.Parameter(torch.ones(2*N, dtype=torch.float32))\n#         self.K = nn.Parameter(torch.rand(2*N) * 100)\n\n    def forward(self, batch):\n        batchin = torch.isin(batch, capital_ids).to(torch.int)\n        i, j = batch[:, 0], batch[:, 1]\n#         return self.A[i] * self.A[j]\n        return self.A[i] * self.A[j] + self.B[i] + self.B[j]\n        # return self.A[i] * self.A[j] + self.M[i] + self.M[j]\n        # return self.A[i] * self.B[j] + self.A[j] * self.B[i] + self.M[i] + self.M[j]\n\nmodel = DemandModel().cuda()\n\nbatch_size = N // 2\nlr = 0.01 / 2 / 2\nstatus_every = 200#N*(N-1) // (batch_size ) / 1000\nepochs = 100\n\nprint(f'*** STARTING: {batch_size}, {lr}, {epochs}')\noptimizer = optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.MSELoss()\n\ndataloader = DataLoader(\n    TensorDataset(xs, ys),\n    batch_size=batch_size,\n    shuffle=True\n)\n\nstart = time.time()\nlosses = []\nlast_model = model\nfor e in range(epochs):\n    total_loss = 0\n    i = 0\n    for batch_x, batch_y in dataloader:\n        optimizer.zero_grad()\n        y_pred = model(batch_x)\n        loss = criterion(y_pred, batch_y)\n        l1 = .002 * sum([p.abs().sum() for p in model.B])\n        loss.backward()\n        optimizer.step()\n        if i > 0 and i % status_every == 0:\n            print(f'{i/len(dataloader)+e:.5f},{math.sqrt(loss)},{l1}')\n        \n        total_loss += loss.item()\n        i += 1\n\n    loss = math.sqrt(total_loss / len(dataloader))\n#     print(f'{e:>5} | loss={loss}')\n\n    torch.save(model.A, f'./models/A-V13_{e}.pt')\n    torch.save(model.B, f'./models/B-V13_{e}.pt')\n#     torch.save(model.C, f'./models/C-V13_{e}.pt')\n#     torch.save(model.K, f'./models/M-V12_{e}.pt')\n\n    if loss < 5e-4:\n        print(f'*** PAST CRITERON: loss={loss}')\n        last_model = model\n        break\n    if loss < 1 and loss > losses[-1]:\n        print(f'*** INCREASING: loss={loss}')\n        break\n    losses.append(loss)\n    last_model = model\n\nprint(f'*** DONE: {time.time() - start:.2f}s')\n# D_pred = torch.mul(last_model.A.unsqueeze(1), last_model.B) + torch.mul(last_model.A, last_model.B.unsqueeze(1))\n# print(D - D_pred)\n# print(torch.sum(torch.abs(D - D_pred)))\n\n# plt.plot(losses, label=f'batch_size={batch_size}, lr={lr}')\n\n# plt.legend()\n# plt.xlabel('Epoch')\n# plt.ylabel('MSE Loss')\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"os.listdir('./models')\nimport shutil\nshutil.copy('./models/A-V7_3.pt', './A-V7_3.pt')\nshutil.copy('./models/M-V7_3.pt', './M-V7_3.pt')\n\n# import shutil\n# shutil.rmtree('models')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for f in os.listdir('./models'):\n    os.remove(f)\n","metadata":{},"execution_count":null,"outputs":[]}]}